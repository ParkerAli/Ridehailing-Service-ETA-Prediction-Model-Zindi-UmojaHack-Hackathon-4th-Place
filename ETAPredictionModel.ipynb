{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Zindi UmojaHack South Africa: Yassir ETA Prediction Challenge by UmojaHack Africa\n",
    "**Team**\n",
    "- Taahir Bhorat\n",
    "- Stuart Mesham\n",
    "- Mahmood-Ali Parker\n",
    "\n",
    "**Date:** 25 July 2020\n",
    " \n",
    "**Time Constraint:** 9 hours\n",
    " \n",
    "**URL:** https://zindi.africa/hackathons/umojahack-south-africa-yassir-eta-prediction-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Spec\n",
    "Ride-hailing apps like Uber and Yassir rely on real-time data and machine learning algorithms to automate their services. Accurately predicting the estimated time of arrival (ETA) for Yassir trips will make Yassirâ€™s services more reliable and attractive; this will have a direct and indirect impact on both customers and business partners. The solution would help the company save money and allocate more resources to other parts of the business.\n",
    "\n",
    "The objective of this hackathon is to predict the estimated time of arrival at the dropoff point for a single Yassir journey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Data\n",
    "The data contains details for 119,549 trips (train and test are split by date). Each row contains a start location and end location (reported as latitude and longitude to within approximately 100m) and the travel distance along the fastest route. Each trip also has a timestamp, which can be used to pull the weather for that day from Weather.csv file. The weather data includes temperature, rainfall and wind speed for the time period during which the trip data was collected.\n",
    " \n",
    "For confidentiality reasons, the data itself isn't present in the repository but the notebook should provide an adequate outlook on our modelling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataframe Population and Feature Engineering\n",
    "It's worth mentioning that we had methods to handle a weather dataframe and join that to our main dataframe based on date. However, we found using weather variables severely decreased performance and therefore ended up omitting weather entirely.\n",
    " \n",
    "The pre_process method processes our dataframe's timestamp column to encode important components of time into their own columns. We only used day of week and hour because we found the other components detracted from our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process(df):    \n",
    "    StartTime = pd.to_datetime(df['Timestamp'], infer_datetime_format=True)\n",
    "    \n",
    "    df['Day_in_week'] = StartTime.dt.dayofweek\n",
    "    df['Hour_in_Day'] = StartTime.dt.hour\n",
    "    df = df.drop('Timestamp', axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The clean_training_set method removes rows with unreasonably high average speeds (faster than 200 km/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_training_set(trips_df):\n",
    "    return trips_df[(trips_df['Trip_distance'] / 1000) / (trips_df['ETA'] / (60 * 60)) <= 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The split_X_y method drops the ETA and ID columns from a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_X_y(df):\n",
    "    return df.drop(['ETA', 'ID'], axis=1), df['ETA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We read in the 'Train.csv' which contains all validatable data we are given for the hackathon into a dataframe. We then sort, clean and pre_process our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train.csv')\n",
    "\n",
    "data = data.sort_values('Timestamp', ascending=False)\n",
    "data = clean_training_set(data)\n",
    "data = pre_process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83904, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we split our data into training and validation sets. We don't have a test set because the hackathon submission fulfills that roll. We use 8000 items for validation (about a 90:10 split) because 8000 items provides adequate data for accurate validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = data.iloc[8000:]\n",
    "val = data.iloc[:8000]\n",
    "X_train, y_train = split_X_y(train)\n",
    "X_val, y_val = split_X_y(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modelling\n",
    "Initially, we used both XGBoost and CatBoost but after extensive experimentation, we got better performance with CatBoost. We did, however use XGBoost's feature importance functionality for some invaluable insights into variable selection for what would eventually be our 4th place model.\n",
    " \n",
    "Our performance metric of choice is root mean squared error (RMSE) as that's what the hackathon spec required.\n",
    "### XGBoost\n",
    "We create our XGBoost Regression model structure first. The model structure was the most effective for XGBoost after extensive extensive testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1126.08\tvalidation_1-rmse:1120.14\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 15 rounds.\n",
      "[200]\tvalidation_0-rmse:124.003\tvalidation_1-rmse:159.849\n",
      "[400]\tvalidation_0-rmse:103.003\tvalidation_1-rmse:153.334\n",
      "Stopping. Best iteration:\n",
      "[534]\tvalidation_0-rmse:94.4361\tvalidation_1-rmse:151.855\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(colsample_bytree=0.8, max_depth=20, max_leaves=120,\n",
       "             min_child_weight=2, n_estimators=7000,\n",
       "             objective='reg:squarederror', subsample=0.7, tree_method='hist')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " objective='reg:squarederror',\n",
    " tree_method='hist',\n",
    " n_estimators=7000,\n",
    " max_depth=20,\n",
    " max_leaves=120,\n",
    " min_child_weight=2,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.8,\n",
    " scale_pos_weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we fit our training data on our model. The early_stopping_rounds are set to 15 to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "    verbose=200, \n",
    "    early_stopping_rounds = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see our best validation accuracy is RMSE = 151. While this could possibly be improved, we'll show that the CatBoost model provided a slightly better predictive performance.\n",
    " \n",
    "We compute feature importances using our xgb1 model next to see which variables are more useful for predicting ETA. This was useful in identifying that weather variables were detrimental to performance. This lead to us ultimately omitting weather variables and certain time components. The lower the values, the less useful the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trip_distance</td>\n",
       "      <td>0.717411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Destination_lon</td>\n",
       "      <td>0.100044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Origin_lon</td>\n",
       "      <td>0.062338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Destination_lat</td>\n",
       "      <td>0.046074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Origin_lat</td>\n",
       "      <td>0.036616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hour_in_Day</td>\n",
       "      <td>0.025214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Day_in_week</td>\n",
       "      <td>0.012304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variable  Importance\n",
       "4    Trip_distance    0.717411\n",
       "3  Destination_lon    0.100044\n",
       "1       Origin_lon    0.062338\n",
       "2  Destination_lat    0.046074\n",
       "0       Origin_lat    0.036616\n",
       "6      Hour_in_Day    0.025214\n",
       "5      Day_in_week    0.012304"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Variable':X_train.columns,\n",
    "              'Importance':xgb1.feature_importances_}).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CatBoost\n",
    "We create our CatBoost Regression model structure next. This model structure was the most effective overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cb1 = CatBoostRegressor(\n",
    "    loss_function='RMSE',\n",
    "    iterations=7000,\n",
    "    grow_policy='Lossguide',\n",
    "    bootstrap_type='Bayesian',\n",
    "    max_leaves=120,\n",
    "    task_type='CPU'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we fit our training data on our model. We didn't use any measures to prevent overfitting because our model was most accurate by completing all the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.031071\n",
      "0:\tlearn: 550.2847104\ttest: 537.1941735\tbest: 537.1941735 (0)\ttotal: 84.6ms\tremaining: 9m 52s\n",
      "200:\tlearn: 175.3634796\ttest: 181.0933405\tbest: 181.0933405 (200)\ttotal: 11.4s\tremaining: 6m 24s\n",
      "400:\tlearn: 157.2134543\ttest: 168.7192825\tbest: 168.7192825 (400)\ttotal: 22.3s\tremaining: 6m 7s\n",
      "600:\tlearn: 146.5637327\ttest: 162.3385801\tbest: 162.3385801 (600)\ttotal: 33.4s\tremaining: 5m 56s\n",
      "800:\tlearn: 139.5812420\ttest: 158.9032908\tbest: 158.9032908 (800)\ttotal: 44.4s\tremaining: 5m 43s\n",
      "1000:\tlearn: 133.9608654\ttest: 156.5615393\tbest: 156.5615393 (1000)\ttotal: 55.4s\tremaining: 5m 31s\n",
      "1200:\tlearn: 129.4984824\ttest: 155.0104922\tbest: 155.0053389 (1198)\ttotal: 1m 5s\tremaining: 5m 18s\n",
      "1400:\tlearn: 125.5763762\ttest: 153.7655379\tbest: 153.7655379 (1400)\ttotal: 1m 15s\tremaining: 5m\n",
      "1600:\tlearn: 122.2885239\ttest: 152.7685718\tbest: 152.7685718 (1600)\ttotal: 1m 24s\tremaining: 4m 45s\n",
      "1800:\tlearn: 119.5511852\ttest: 151.9945630\tbest: 151.9945630 (1800)\ttotal: 1m 32s\tremaining: 4m 26s\n",
      "2000:\tlearn: 117.0657877\ttest: 151.2904500\tbest: 151.2904500 (2000)\ttotal: 1m 39s\tremaining: 4m 8s\n",
      "2200:\tlearn: 114.6755968\ttest: 150.5847337\tbest: 150.5847337 (2200)\ttotal: 1m 46s\tremaining: 3m 53s\n",
      "2400:\tlearn: 112.5461751\ttest: 150.1276392\tbest: 150.1276392 (2400)\ttotal: 1m 54s\tremaining: 3m 39s\n",
      "2600:\tlearn: 110.5711239\ttest: 149.6442660\tbest: 149.6442660 (2600)\ttotal: 2m 1s\tremaining: 3m 25s\n",
      "2800:\tlearn: 108.7666635\ttest: 149.1944051\tbest: 149.1937192 (2799)\ttotal: 2m 8s\tremaining: 3m 12s\n",
      "3000:\tlearn: 107.0212644\ttest: 148.9010918\tbest: 148.8982140 (2988)\ttotal: 2m 15s\tremaining: 3m\n",
      "3200:\tlearn: 105.4256528\ttest: 148.5451472\tbest: 148.5441076 (3197)\ttotal: 2m 22s\tremaining: 2m 49s\n",
      "3400:\tlearn: 104.0027267\ttest: 148.2349080\tbest: 148.2310354 (3395)\ttotal: 2m 28s\tremaining: 2m 37s\n",
      "3600:\tlearn: 102.6162798\ttest: 148.0111991\tbest: 148.0089953 (3599)\ttotal: 2m 34s\tremaining: 2m 26s\n",
      "3800:\tlearn: 101.3558622\ttest: 147.8520328\tbest: 147.8456297 (3797)\ttotal: 2m 40s\tremaining: 2m 15s\n",
      "4000:\tlearn: 100.0814033\ttest: 147.6419579\tbest: 147.6419579 (4000)\ttotal: 2m 47s\tremaining: 2m 5s\n",
      "4200:\tlearn: 98.8886444\ttest: 147.5641723\tbest: 147.5570686 (4192)\ttotal: 2m 53s\tremaining: 1m 55s\n",
      "4400:\tlearn: 97.7869935\ttest: 147.4029288\tbest: 147.4029288 (4400)\ttotal: 2m 59s\tremaining: 1m 46s\n",
      "4600:\tlearn: 96.6770575\ttest: 147.2568462\tbest: 147.2542014 (4575)\ttotal: 3m 5s\tremaining: 1m 36s\n",
      "4800:\tlearn: 95.6511369\ttest: 147.1400531\tbest: 147.1375849 (4799)\ttotal: 3m 11s\tremaining: 1m 27s\n",
      "5000:\tlearn: 94.6895635\ttest: 147.0774253\tbest: 147.0774253 (5000)\ttotal: 3m 16s\tremaining: 1m 18s\n",
      "5200:\tlearn: 93.7402454\ttest: 146.9259677\tbest: 146.9241714 (5199)\ttotal: 3m 22s\tremaining: 1m 10s\n",
      "5400:\tlearn: 92.8676422\ttest: 146.8315562\tbest: 146.8315562 (5400)\ttotal: 3m 28s\tremaining: 1m 1s\n",
      "5600:\tlearn: 92.0260012\ttest: 146.7351903\tbest: 146.7295304 (5592)\ttotal: 3m 34s\tremaining: 53.6s\n",
      "5800:\tlearn: 91.2105636\ttest: 146.6962649\tbest: 146.6893265 (5675)\ttotal: 3m 40s\tremaining: 45.6s\n",
      "6000:\tlearn: 90.4034023\ttest: 146.6003414\tbest: 146.6003414 (6000)\ttotal: 3m 46s\tremaining: 37.7s\n",
      "6200:\tlearn: 89.6383127\ttest: 146.5486568\tbest: 146.5484865 (6199)\ttotal: 3m 53s\tremaining: 30.1s\n",
      "6400:\tlearn: 88.9174119\ttest: 146.4746502\tbest: 146.4629350 (6389)\ttotal: 3m 59s\tremaining: 22.4s\n",
      "6600:\tlearn: 88.2213750\ttest: 146.4175899\tbest: 146.4175899 (6600)\ttotal: 4m 5s\tremaining: 14.8s\n",
      "6800:\tlearn: 87.5318283\ttest: 146.3786502\tbest: 146.3694281 (6741)\ttotal: 4m 10s\tremaining: 7.34s\n",
      "6999:\tlearn: 86.8518096\ttest: 146.3428246\tbest: 146.3293436 (6977)\ttotal: 4m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 146.3293436\n",
      "bestIteration = 6977\n",
      "\n",
      "Shrink model to first 6978 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x258ebf6efc8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb1.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_val, y_val),\n",
    "    verbose=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "We can see our best validation accuracy is RMSE = 146. This is the final model that got our team 4th place. We got this result less than an hour before the deadline so it's fair to assume that there's room for at least a little improvement.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
